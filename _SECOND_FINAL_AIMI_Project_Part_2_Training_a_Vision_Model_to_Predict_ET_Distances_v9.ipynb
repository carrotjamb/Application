{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carrotjamb/AIMI-Intern-Part-2-Files/blob/main/_SECOND_FINAL_AIMI_Project_Part_2_Training_a_Vision_Model_to_Predict_ET_Distances_v9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMfGLGNLnXk7"
      },
      "source": [
        "## AIMI High School Internship 2023 - Classification Model\n",
        "### Notebook 2: Training a Vision Model to Predict ET Distances\n",
        "\n",
        "**The Problem**: Given a chest X-ray, our goal in this project is to predict the distance from an endotracheal tube to the carina. This is an important clinical task - endotracheal tubes that are positioned too far (>5cm) above the carina will not work effectively.\n",
        "\n",
        "**Your Second Task**: You should now have a training dataset consisting of (a) chest X-rays and (b) annotations indicating the distance of the endotracheal tube from the carina. Now, your goal is to train a computer vision model to predict endotracheal tube distance from the image. You have **two options** for this task, and you may attempt one or both of these:\n",
        "- *Distance Categorization* : Train a model to determine whether the position of a tube is abnormal (>5.0 cm) or normal (â‰¤ 5.0 cm).\n",
        "- *Distance Prediction*: Train a model that predicts the distance of the endotracheal tube from the carina in centimeters.\n",
        "\n",
        "In this notebook, we provide some simple starter code to get you started on training a computer vision model. You are not required to use this template - feel free to modify as you see fit.\n",
        "\n",
        "**Submitting Your Model**: We have created a leaderboard where you can submit your model and view results on the held-out test set. We provide instructions below for submitting your model to the leaderboard. **Please follow these directions carefully**.\n",
        "\n",
        "We will evaluate your results on the held-out test set with the following evaluation metrics:\n",
        "- *Distance Categorization* : We will measure AUROC, which is a metric commonly used in healthcare tasks. See this blog for a good explanation of AUROC: https://glassboxmedicine.com/2019/02/23/measuring-performance-auc-auroc/\n",
        "- *Distance Prediction*: We will measure the mean average error (also known as L1 distance) between the predicted distances and the true distances.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ1rTMrgpoil"
      },
      "source": [
        "## Load Data\n",
        "Before you begin, make sure to go to `Runtime` > `Change Runtime Type` and select a T4 GPU. Then, upload `data.zip`. It should take about 10 minutes for these files to be uploaded. Then, run the following cells to unzip the dataset (which should take < 10 seconds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytMQzLJindpR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZQ1h6dcsQ-4"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/Colab\\ Notebooks/drive-download-20230620T044532Z-001\\ \\(1\\).zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySb9AsmBp-Gz"
      },
      "outputs": [],
      "source": [
        "!unzip -qq /content/mimic-train.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bqeesviqp_hN"
      },
      "outputs": [],
      "source": [
        "!unzip -qq /content/mimic-test.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5etX4eYtu_s"
      },
      "source": [
        "## Import Libraries\n",
        "We are leveraging the PyTorch framework to train our models. For more information and tutorials on PyTorch, see this link: https://pytorch.org/tutorials/beginner/basics/intro.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzhTFDi7tuPK"
      },
      "outputs": [],
      "source": [
        "# Some libraries that you may find useful are included here.\n",
        "# To import a library that isn't provided with Colab, use the following command: !pip install torchmetrics\n",
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "from torch.utils.data.dataset import TensorDataset\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "\n",
        "#Set up GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNxRvkt67W2I"
      },
      "outputs": [],
      "source": [
        "filename_1 = \"/content/mimic_train_student.csv\"\n",
        "list_of_keys = []\n",
        "\n",
        "with open(filename_1, 'r') as csvfile:\n",
        "    datareader = csv.reader(csvfile)\n",
        "    for row in datareader:\n",
        "        img_path = \"/content/\" + str(row[4])\n",
        "        list_of_keys.append(img_path)\n",
        "\n",
        "filename_2 = \"/content/drive/MyDrive/Colab Notebooks/CSVs_from_part_1 /csv-part-2-v2-(results_1.16).csv\"\n",
        "list_of_labels = []\n",
        "\n",
        "with open(filename_2, 'r') as csvfile:\n",
        "    datareader = csv.reader(csvfile)\n",
        "    for row in datareader:\n",
        "        list_of_labels.append(row[1])\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/CSVs_from_part_1 /For Part 2/csv-tester.csv', 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    reader = csv.reader(f)\n",
        "    writer.writerows(zip(list_of_keys, list_of_labels))\n",
        "\n",
        "input = open('/content/drive/MyDrive/Colab Notebooks/CSVs_from_part_1 /For Part 2/csv-tester.csv', 'r')\n",
        "output = open('/content/drive/MyDrive/Colab Notebooks/CSVs_from_part_1 /For Part 2/csv-tester-removed.csv', 'w')\n",
        "writer = csv.writer(output)\n",
        "for row in csv.reader(input):\n",
        "    if row[1] != \"0.0\" and row[1] != \"\":\n",
        "        writer.writerow(row)\n",
        "\n",
        "#Get training set - 75% of\n",
        "input = open('/content/drive/MyDrive/Colab Notebooks/CSVs_from_part_1 /For Part 2/csv-tester-removed.csv', 'r')\n",
        "output = open('/content/drive/MyDrive/Colab Notebooks/CSVs_from_part_1 /For Part 2/csv-training-set.csv', 'w')\n",
        "writer2 = csv.writer(output)\n",
        "count = 0\n",
        "\n",
        "for row in csv.reader(input):\n",
        "    count += 1\n",
        "    if count < (0.75)*(len(list_of_keys)):\n",
        "        writer2.writerow(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4rUq8x6uWew"
      },
      "outputs": [],
      "source": [
        "#Get validation set - 25% of\n",
        "input = open('/content/drive/MyDrive/Colab Notebooks/CSVs_from_part_1 /For Part 2/csv-tester-removed.csv', 'r')\n",
        "output = open('/content/drive/MyDrive/Colab Notebooks/CSVs_from_part_1 /For Part 2/csv-validation-set.csv', 'w')\n",
        "writer2 = csv.writer(output)\n",
        "count = 0\n",
        "\n",
        "writer2.writerow(['/content/image_path', 'measurement'])\n",
        "\n",
        "for row in csv.reader(input):\n",
        "    count += 1\n",
        "    if count >= (0.75)*(len(list_of_keys)):\n",
        "        writer2.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY7yvIM0yl4M"
      },
      "source": [
        "# Create Dataloaders\n",
        "We will implement a custom Dataset class to load in data. A custom Dataset class must have three methods: `__init__`, which sets up any class variables, `__len__`, which defines the total number of images, and `__getitem__`, which returns a single image and its paired label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwH5586UqAnY"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class ChestXRayDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file_key, transform=None, **kwargs):\n",
        "        super(ChestXRayDataset, self).__init__(**kwargs)\n",
        "\n",
        "        # # Fill in __init__() here\n",
        "        # self.chest_xray_labels = pd.read_csv(csv_file_labels)\n",
        "        self.chest_xray_key = pd.read_csv(csv_file_key)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        # Fill in __len__() here\n",
        "        length = len(self.chest_xray_key)\n",
        "        return length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        out_dict = {\"idx\": torch.tensor(idx),}\n",
        "        convert_tensor = transforms.ToTensor()\n",
        "\n",
        "        # Fill in __getitem__() here\n",
        "        #Read in Image as\n",
        "        img_name = self.chest_xray_key['/content/image_path'][idx]\n",
        "        img = cv2.imread(img_name)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = convert_tensor(img)\n",
        "\n",
        "        mean = [0.485, 0.456, 0.406]\n",
        "        std = [0.229, 0.224, 0.225]\n",
        "\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((224,224)),\n",
        "            transforms.Normalize(mean, std),\n",
        "        ])\n",
        "\n",
        "        normalized_image = transform(img)\n",
        "        out_dict[\"img\"] = normalized_image\n",
        "\n",
        "        #Convert measurement to category (abnormal if measurement greater than 5.0 cm, otherwise normal)\n",
        "        measurement = self.chest_xray_key['measurement'][idx]\n",
        "\n",
        "        label = 0\n",
        "        if measurement > 5.0:\n",
        "          #1 Corresponds to Abnormal\n",
        "          label = 1.0\n",
        "        else:\n",
        "          #0 Corresponds to Normal\n",
        "          label = 0.0\n",
        "\n",
        "        out_dict[\"label\"] = torch.tensor(label)\n",
        "\n",
        "        return out_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oGRC8Mk0ytJ"
      },
      "source": [
        "# Define Training Components\n",
        "Here, define any necessary components that you need to train your model, such as the model architecture, the loss function, and the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-HeB-_-k0x_S"
      },
      "outputs": [],
      "source": [
        "# Model Architecture\n",
        "# model_ft = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', weights='ResNet50_Weights.IMAGENET1K_V1')\n",
        "model = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1')\n",
        "\n",
        "#Set Model Feature Output to 1\n",
        "num_ftrs = model.fc.in_features\n",
        "new_layer = nn.Linear(num_ftrs, 1)\n",
        "model.fc = new_layer\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss Function\n",
        "loss = nn.BCELoss()\n",
        "\n",
        "#Optimizer\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=9e-5) # AdamW is a commonly-used optimizer. Feel free to modify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXvOaNPB1OGH"
      },
      "source": [
        "## Training Code\n",
        "We provide starter code below that implements a simple training loop in PyTorch. Feel free to modify as you see fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWnzKime0exc"
      },
      "outputs": [],
      "source": [
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "def train(model, loss_fn, train_loader, opt, max_epoch, validation_loader):\n",
        "  for epoch in range(0, max_epoch):\n",
        "      #Training\n",
        "      model.train()\n",
        "      total_loss = 0.\n",
        "      correct_train = 0.\n",
        "      num_batches = len(train_loader)\n",
        "      count = 0\n",
        "      #Loop through training set\n",
        "      for step, sample in tqdm(enumerate(train_loader)):\n",
        "        count += 1\n",
        "        #Send image/labels to gpu\n",
        "        image = sample['img'].to(device)\n",
        "        labels = sample['label'].to(device)\n",
        "        labels = labels.unsqueeze(dim=1) #Converts labels to (16, 1) tensor\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        pred = model(image)\n",
        "        pred = sigmoid(pred)\n",
        "\n",
        "        loss = loss_fn(pred, labels)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if count % 10 == 0:\n",
        "          print(loss)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        #Compute average loss\n",
        "        print(\"Average Loss:\", total_loss/count)\n",
        "\n",
        "        #Count number of accurate predictions\n",
        "        correct_train += (pred.round() == labels).sum().item()\n",
        "\n",
        "        #Compute accuracy\n",
        "        accuracy = correct_train/(count*16)\n",
        "        print(\"Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "      # #Validation\n",
        "      # model.eval()\n",
        "      # total_loss = 0.\n",
        "      # correct_train = 0.\n",
        "      # num_batches = len(validation_loader)\n",
        "      # # test_loss, correct = 0, 0\n",
        "      # with torch.no_grad():\n",
        "      #   total_correct = 0\n",
        "      #   total_samples = 0\n",
        "\n",
        "      #   for step, sample in tqdm(enumerate(validation_loader)):\n",
        "      #     sample['img'], sample['label'] = sample['img'].to(device), sample['label'].to(device)\n",
        "\n",
        "      #     pred = model(sample['img'])\n",
        "      #     pred = sigmoid(pred)\n",
        "      #     pred = torch.round(pred)\n",
        "\n",
        "      #     labels2 = sample['label']\n",
        "      #     labels2 = labels2.unsqueeze(dim=1)\n",
        "\n",
        "      #     #Calculate Loss\n",
        "      #     loss = loss_fn(pred, labels2)\n",
        "      #     #Add Loss to Total Loss\n",
        "      #     total_loss += loss.item()\n",
        "\n",
        "      #     #Count number of accurate predictions\n",
        "      #     correct_train += (pred == labels2).sum().item()\n",
        "\n",
        "      #   #Compute average loss\n",
        "      #   print(\"Average Loss:\", total_loss/num_batches)\n",
        "\n",
        "      #   #Compute accuracy\n",
        "      #   accuracy = correct_train/(32 * num_batches)\n",
        "      #   print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWl9WNpX454H"
      },
      "outputs": [],
      "source": [
        "#Create Dataset and Dataloader\n",
        "training_dataset = ChestXRayDataset(\"/content/drive/MyDrive/Colab Notebooks/CSVs_from_part_1 /For Part 2/csv-training-set.csv\")\n",
        "training_dataloader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
        "validation_dataset = ChestXRayDataset('/content/drive/MyDrive/Colab Notebooks/CSVs_from_part_1 /For Part 2/csv-validation-set.csv')\n",
        "validation_data_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=16, shuffle=False, drop_last=False)\n",
        "\n",
        "train(model, loss, training_dataloader, opt, max_epoch=3, validation_loader=validation_data_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8F_1wzY6I7j"
      },
      "source": [
        "## Submitting Your Results\n",
        "Once you have successfully trained your model, generate predictions on the test set and save your results as a `.csv` file. This file can then be uploaded to the leaderboard.\n",
        "\n",
        "Your final `.csv` file **must** have the following format:\n",
        "- There must be a column titled `image_path` with the paths to the test set images. This column should be identical to the one provided in `mimic_test_student.csv`.\n",
        "- There must be a column titled `pred` with your model outputs.\n",
        "  - If you are running the `distance categorization` task, this column must have floating point numbers ranging between 0 and 1. Higher numbers should indicate a greater likelihood that the tube distance is abnormal. Hint: You can convert model outputs to the 0 to 1 range by applying the sigmoid activation function (torch.nn.sigmoid())\n",
        "  - If you are running the `distance prediction` task, this column must have numbers representing the tube distance in centimeters.\n",
        "- Double check that there are 500 rows in your output file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SDWeda0jc2h"
      },
      "outputs": [],
      "source": [
        "#Get list of predictions\n",
        "\n",
        "# model = # Model Architecture\n",
        "# ckpt = torch.load(\"/content/drive/MyDrive/best.pkl\")\n",
        "# model.load_state_dict(ckpt[\"state_dict\"])\n",
        "filename_3 = \"/content/drive/MyDrive/test_results_final_4.csv\"\n",
        "\n",
        "\n",
        "test_dataset = ChestXRayDataset(\"/content/drive/MyDrive/test_key_2.csv\")\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False, drop_last=False)\n",
        "\n",
        "test_results = {\"image_path\": [], \"pred\": []}\n",
        "# Write method to load in data from test_loader, compute model predictions, and append results to test_results dict\n",
        "\n",
        "with open(filename_3, 'w') as csvfile3:\n",
        "    datawriter = csv.writer(csvfile3)\n",
        "    with torch.no_grad():\n",
        "      datawriter.writerow([\"pred\"])\n",
        "      for step, sample in tqdm(enumerate(test_loader)):\n",
        "\n",
        "        sample['img'], sample['label'] = sample['img'].to(device), sample['label'].to(device)\n",
        "\n",
        "        pred = model(sample['img'])\n",
        "        pred = sigmoid(pred)\n",
        "        print(pred)\n",
        "        # pred = torch.round(pred)\n",
        "        datawriter.writerow([pred.item()])\n",
        "        count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQOavII6kwcS"
      },
      "outputs": [],
      "source": [
        "#Create List of Filenames\n",
        "total = 0\n",
        "\n",
        "filename_1 = \"/content/mimic_test_student.csv\"\n",
        "filename_2 = \"/content/drive/MyDrive/test_key_2.csv\"\n",
        "list_of_keys = []\n",
        "with open(filename_1, 'r') as csvfile:\n",
        "  with open(filename_2, 'w') as csvfile2:\n",
        "    datareader = csv.reader(csvfile)\n",
        "    datawriter = csv.writer(csvfile2)\n",
        "    datawriter.writerow(['/content/image_path', 'measurement'])\n",
        "    count = 1\n",
        "    for row in datareader:\n",
        "        if count != 1:\n",
        "          filepath = '/content/' + row[5]\n",
        "          datawriter.writerow([filepath, \"\"])\n",
        "        count +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5osagFf5Fox"
      },
      "outputs": [],
      "source": [
        "#Validation\n",
        "validation_dataset = ChestXRayDataset('/content/drive/MyDrive/Colab Notebooks/CSVs_from_part_1 /For Part 2/csv-validation-set.csv')\n",
        "validation_data_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=16, shuffle=False, drop_last=False)\n",
        "\n",
        "write = csv.writer(open(\"/content/drive/MyDrive/Colab Notebooks/CSVs_from_part_1 /validation_results2.csv\", 'w'))\n",
        "write.writerow(['prediction', 'label'])\n",
        "sigmoid = nn.Sigmoid()\n",
        "total = 0\n",
        "model.eval()\n",
        "num_batches = len(validation_data_loader)\n",
        "# test_loss, correct = 0, 0\n",
        "with torch.no_grad():\n",
        "  total_correct = 0.\n",
        "\n",
        "  total_loss = 0.\n",
        "  total_samples = 0.\n",
        "  correct_train = 0.\n",
        "  count = 0\n",
        "\n",
        "  for step, sample in tqdm(enumerate(validation_data_loader)):\n",
        "    count += 1\n",
        "    sample['img'], sample['label'] = sample['img'].to(device), sample['label'].to(device)\n",
        "\n",
        "    pred = model(sample['img'])\n",
        "    pred = sigmoid(pred)\n",
        "    pred = torch.round(pred)\n",
        "\n",
        "    labels2 = sample['label']\n",
        "    labels2 = labels2.unsqueeze(dim=1)\n",
        "\n",
        "    #Calculate Loss\n",
        "    _loss = loss(pred, labels2)\n",
        "    #Add Loss to Total Loss\n",
        "    total_loss += _loss.item()\n",
        "\n",
        "    #Count number of accurate predictions\n",
        "    correct_train += (pred == labels2).sum().item()\n",
        "    print(\"Average Loss:\", total_loss/count)\n",
        "\n",
        "\n",
        "  #Compute accuracy\n",
        "  accuracy = correct_train/(16 * count)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "\n",
        "  write.writerow([pred, labels2])\n",
        "\n",
        "# def test(dataloader, model, loss_fn):\n",
        "#     size = len(dataloader.dataset)\n",
        "#     num_batches = len(dataloader)\n",
        "#     model.eval()\n",
        "#     test_loss, correct = 0, 0\n",
        "#     with torch.no_grad():\n",
        "#         for step, sample in tqdm(enumerate(dataloader)):\n",
        "#             sample['img'], sample['label'] = sample['img'].to(device), sample['label'].to(device)\n",
        "\n",
        "#             pred = model(sample['img'])\n",
        "#             pred = sigmoid(pred)\n",
        "\n",
        "#             print((sample['label']))\n",
        "#             print(pred)\n",
        "\n",
        "#             write.writerow([list[pred], list[sample['label']]])\n",
        "# #     # test_loss += loss_fn(pred, y).item()\n",
        "# #     #         correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "# #     # test_loss /= num_batches\n",
        "# #     # correct /= size\n",
        "# #     # print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "# # ckpt = torch.load(\"/content/best.pkl\")\n",
        "# # model.load_state_dict(ckpt[\"state_dict\"])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bK3_XQEi7q2"
      },
      "outputs": [],
      "source": [
        "#Create List of Filenames without /content/\n",
        "\n",
        "+# model = # Model Architecture\n",
        "# ckpt = torch.load(\"/content/drive/MyDrive/best.pkl\")\n",
        "# model.load_state_dict(ckpt[\"state_dict\"])\n",
        "filename_3 = \"/content/drive/MyDrive/test_key.csv\"\n",
        "filename_4 =  \"/content/drive/MyDrive/test_key_2.csv\"\n",
        "\n",
        "# test_dataset = ChestXRayDataset(\"/content/drive/MyDrive/test_key.csv\")\n",
        "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False, drop_last=False)\n",
        "\n",
        "# test_results = {\"image_path\": [], \"pred\": []}\n",
        "# # Write method to load in data from test_loader, compute model predictions, and append results to test_results dict\n",
        "with open(filename_4, 'w') as csvfile4:\n",
        "    datawriter = csv.writer(csvfile4)\n",
        "    with open(filename_3, 'r') as csvfile3:\n",
        "        datareader = csv.writer(csvfile3)\n",
        "    #     with torch.no_grad():\n",
        "    #       total_correct = 0.\n",
        "\n",
        "    #       total_loss = 0.\n",
        "    #       total_samples = 0.\n",
        "    #       correct_train = 0.\n",
        "    #       count = 0\n",
        "\n",
        "        for row in csvfile3:\n",
        "          if row[0].startswith(\"/content/\"):\n",
        "            answer = row[0][9:]\n",
        "            datawriter.writerow([answer])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OStU63uudg_8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}